{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python vs pandas vs pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName(\n",
    "    \"Counting word occurences from a book.\"\n",
    ").getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_file = \"../../data/gutenberg_books/1342-0.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words_with_pyspark():\n",
    "    # If you need to read multiple text files, replace `1342-0` by `*`.\n",
    "    results = (\n",
    "        spark.read.text(single_file)\n",
    "        .select(F.split(F.col(\"value\"), \" \").alias(\"line\"))\n",
    "        .select(F.explode(F.col(\"line\")).alias(\"word\"))\n",
    "        .select(F.lower(F.col(\"word\")).alias(\"word\"))\n",
    "        .select(F.regexp_extract(F.col(\"word\"), \"[a-z']*\", 0).alias(\"word\"))\n",
    "        .where(F.col(\"word\") != \"\")\n",
    "        .groupby(F.col(\"word\"))\n",
    "        .count()\n",
    "    )\n",
    "\n",
    "    return results.orderBy(\"count\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|word|count|\n",
      "+----+-----+\n",
      "| the| 4480|\n",
      "|  to| 4218|\n",
      "|  of| 3711|\n",
      "| and| 3504|\n",
      "| her| 2199|\n",
      "|   a| 1982|\n",
      "|  in| 1909|\n",
      "| was| 1838|\n",
      "|   i| 1749|\n",
      "| she| 1668|\n",
      "|that| 1487|\n",
      "|  it| 1482|\n",
      "| not| 1427|\n",
      "| you| 1300|\n",
      "|  he| 1296|\n",
      "|  be| 1257|\n",
      "| his| 1247|\n",
      "|  as| 1174|\n",
      "| had| 1170|\n",
      "|with| 1092|\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = count_words_with_pyspark()\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536 ms ± 9.71 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "\n",
    "results = count_words_with_pyspark()\n",
    "results.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "def count_words_with_python():\n",
    "    word_counter = Counter()\n",
    "    with open(single_file, \"r\", encoding=\"utf-8\") as fh:\n",
    "        for line in fh:\n",
    "            words = [re.search(\"([a-z]*)\", w.lower()).group(1) for w in line.split()]\n",
    "            words = [w for w in words if w]\n",
    "            word_counter.update(Counter(words))\n",
    "    \n",
    "    return word_counter\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 4479),\n",
       " ('to', 4218),\n",
       " ('of', 3711),\n",
       " ('and', 3504),\n",
       " ('her', 2199),\n",
       " ('a', 1982),\n",
       " ('in', 1909),\n",
       " ('was', 1838),\n",
       " ('i', 1750),\n",
       " ('she', 1668),\n",
       " ('that', 1487),\n",
       " ('it', 1482),\n",
       " ('not', 1427),\n",
       " ('you', 1301),\n",
       " ('he', 1296),\n",
       " ('be', 1257),\n",
       " ('his', 1247),\n",
       " ('as', 1174),\n",
       " ('had', 1170),\n",
       " ('with', 1092)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = count_words_with_python()\n",
    "results.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180 ms ± 3.34 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "results = count_words_with_python()\n",
    "results.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def count_words_with_pandas():\n",
    "    df = pd.read_csv(single_file, sep=r\"\\n\", header=None, engine=\"python\")\n",
    "    s = df.iloc[:,0].str.split().explode().str.lower()\n",
    "    df = s.str.extract(\"([a-z]*)\").reset_index(drop=True)\n",
    "    df = df[(df != \"\")].dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the     4480\n",
       "to      4218\n",
       "of      3711\n",
       "and     3504\n",
       "her     2199\n",
       "a       1982\n",
       "in      1909\n",
       "was     1838\n",
       "i       1750\n",
       "she     1668\n",
       "that    1487\n",
       "it      1482\n",
       "not     1427\n",
       "you     1301\n",
       "he      1296\n",
       "be      1257\n",
       "his     1247\n",
       "as      1174\n",
       "had     1170\n",
       "with    1092\n",
       "dtype: int64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = count_words_with_pandas()\n",
    "df.value_counts()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 ms ± 19.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "df = count_words_with_pandas()\n",
    "df.value_counts()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multiple files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"../../data/gutenberg_books/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words_with_pyspark():\n",
    "    # If you need to read multiple text files, replace `1342-0` by `*`.\n",
    "    results = (\n",
    "        spark.read.text(dir)\n",
    "        .select(F.split(F.col(\"value\"), \" \").alias(\"line\"))\n",
    "        .select(F.explode(F.col(\"line\")).alias(\"word\"))\n",
    "        .select(F.lower(F.col(\"word\")).alias(\"word\"))\n",
    "        .select(F.regexp_extract(F.col(\"word\"), \"[a-z']*\", 0).alias(\"word\"))\n",
    "        .where(F.col(\"word\") != \"\")\n",
    "        .groupby(F.col(\"word\"))\n",
    "        .count()\n",
    "    )\n",
    "\n",
    "    return results.orderBy(\"count\", ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+\n",
      "|word|count|\n",
      "+----+-----+\n",
      "| the|38895|\n",
      "| and|23919|\n",
      "|  of|21199|\n",
      "|  to|20526|\n",
      "|   a|14464|\n",
      "|   i|13973|\n",
      "|  in|12777|\n",
      "|that| 9623|\n",
      "|  it| 9099|\n",
      "| was| 8920|\n",
      "| her| 7923|\n",
      "|  my| 7385|\n",
      "| his| 6642|\n",
      "|with| 6575|\n",
      "|  he| 6444|\n",
      "|  as| 6439|\n",
      "| you| 6295|\n",
      "| had| 5718|\n",
      "| she| 5617|\n",
      "| for| 5425|\n",
      "+----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = count_words_with_pyspark()\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.18 s ± 68 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "results = count_words_with_pyspark()\n",
    "results.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "def count_words_with_python():\n",
    "    word_counter = Counter()\n",
    "    \n",
    "    for file in Path(dir).glob(\"*.txt\"):    \n",
    "        with open(file, \"r\", encoding=\"utf-8\") as fh:\n",
    "            for line in fh:\n",
    "                words = [re.search(\"([a-z]*)\", w.lower()).group(1) for w in line.split()]\n",
    "                words = [w for w in words if w]\n",
    "                word_counter.update(Counter(words))\n",
    "    \n",
    "    return word_counter\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 38894),\n",
       " ('and', 23919),\n",
       " ('of', 21199),\n",
       " ('to', 20526),\n",
       " ('a', 14464),\n",
       " ('i', 13974),\n",
       " ('in', 12777),\n",
       " ('that', 9623),\n",
       " ('it', 9099),\n",
       " ('was', 8920),\n",
       " ('her', 7923),\n",
       " ('my', 7385),\n",
       " ('his', 6642),\n",
       " ('with', 6575),\n",
       " ('he', 6444),\n",
       " ('as', 6439),\n",
       " ('you', 6297),\n",
       " ('had', 5718),\n",
       " ('she', 5617),\n",
       " ('for', 5425)]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = count_words_with_python()\n",
    "results.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.08 s ± 3.71 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit \n",
    "\n",
    "results = count_words_with_python()\n",
    "results.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def count_words_with_pandas():\n",
    "    df = pd.concat([pd.read_csv(file, sep=r\"\\n\", header=None, engine=\"python\") for file in Path(dir).glob(\"*.txt\")])\n",
    "    s = df.iloc[:,0].str.split().explode().str.lower()\n",
    "    df = s.str.extract(\"([a-z]*)\").reset_index(drop=True)\n",
    "    df = df[(df != \"\")].dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the     38895\n",
       "and     23919\n",
       "of      21199\n",
       "to      20526\n",
       "a       14464\n",
       "i       13974\n",
       "in      12777\n",
       "that     9623\n",
       "it       9099\n",
       "was      8920\n",
       "her      7923\n",
       "my       7385\n",
       "his      6642\n",
       "with     6575\n",
       "he       6444\n",
       "as       6439\n",
       "you      6297\n",
       "had      5718\n",
       "she      5617\n",
       "for      5425\n",
       "dtype: int64"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = count_words_with_pandas()\n",
    "df.value_counts()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.18 s ± 50.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "df = count_words_with_pandas()\n",
    "df.value_counts()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ed3b52db287b4a5df29473a599c0c2e9f2908e1b4c36ea301cf500c1489a061a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('pyspark')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
